---
title: "Time Series Final"
author: "Steve Bramhall"
date: "August 13, 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(astsa)
library(tswge)
library(vars)
library(RColorBrewer)
library(dplyr)
library(GGally)
library(nnfor)
library(psych)
```


1. Plot the respiratory mortality data.

```{r Prob 1, results="hide"}
data(lap) # import data
data=data.frame(date=time(lap),Time=as.factor(seq(1,508,1)),as.matrix(lap)) # create data frame of data

# plot the resp mortality
plotts.sample.wge(data$rmort)
acf(data$rmort[1:254])   # acf stationarity check
acf(data$rmort[255:508]) # acf stationarity check
```


2. Comment on stationarity or nonstationarity.

The realization for respiratory mortality shows some pseudo cyclic behavior which makes sense since the data is weekly. The variance does not appear constant over time due to the pseudo cyclic spikes. The lags do not appear to be dependent on time as indicated by their divided ACFs. The evidence suggests nonstationarity. Since the data is weekly this is expected and the seasonality will be removed.

3a. Perform a univariate analysis using AR, ARMA, ARMIA or ARUMA. Clearly explain how you arrived at your final model. Build a neural network based model. Build an ensemble model between the two models.

```{r Prob 3a.a - Univariate ARUMA Model}
# since the data is weekly, remove weekly trend
dif1 = artrans.wge(data$rmort,c(rep(0,51),1))     

# some fairly strong autocorrelation seen so let's remove some trend
dif2 = artrans.wge(dif1,1)
acf(dif2,lag.max=50)
# now we are closer to being white

# Perform model selection
aic5.wge(dif2)
# AIC picks ARMA(3,2)

aic5.wge(dif2,type = "bic")
# BIC picks ARMA(1,0)

# get estimates using the BIC recommended AR(1)
estAR1=est.arma.wge(dif2,p=1,q=0)

# get estimates using the AIC recommended ARMA(3,2)
estARMA32=est.arma.wge(dif2,p=3,q=2)

# with the AR(1) estimated parameters, let's create a forecast of the last 30 values
foreAR1=fore.aruma.wge(data$rmort[400:508],phi=estAR1$phi,theta=estAR1$theta,n.ahead=30,s=52,d=1,lastn=T)

# with the ARMA(3,2) estimated parameters, let's create a forecast of the last 30 values
foreARMA32=fore.aruma.wge(data$rmort[400:508],phi=estARMA32$phi,theta=estARMA32$theta,n.ahead=30,s=52,d=1,lastn=T)

# Get ASE from AR(1) estimates
ASE1 = mean((data$rmort[(508-30+1):508]-foreAR1$f)^2)
ASE1

# Get ASE from ARMA(3,2) estimates
ASE2 = mean((data$rmort[(508-30+1):508]-foreARMA32$f)^2)
ASE2

# The ARUMA BIC recommended model with an ASE=3.44 is the selected ARUMA model.
# forecast next 5 points with BCX ARUMA
foreAR1.new=fore.aruma.wge(data$rmort[400:508],phi=estAR1$phi,theta=estAR1$theta,n.ahead=5,s=52,d=1,lastn=F)

```

Since the data is weekly, the weekly seasonality was removed. Although trend was not seen, there was still some strong autocorrelations so another difference was performed to obtain data that more closely resembled white noise. Four to five autocorrelations were greater than the limits (with two-three barely out) and out of fifty autocorrelations this is acceptable. The first two autocorrelations and strong which suggests an AR2.

Then AIC was used to select a model and an AR(3,2) model was selected. Using BIC as the selection criteria, an AR(1) model was selected. Since the AIC and BIC did not agree on the same model both were used to create an ARUMA forecast. It should be noted that the estimated ARMA(3,2) had a root with an Absolute Reciprical = 0.9623 at a System Freq = .1927. Both estimated models has system frequencies at 0.5 with Absolute Recipricals at ~0.35.  The parameters for the AR(1) and ARMA(3,2) were used to create ARUMA forecasts for the last 30 weeks.

The ASE was calculated for both models using their predicted values and the actual values. The ARUMA model with AR(1) estimated parameters (BIC recommended) produced an ASE = 3.44117 and the ARUMA model with ARMA(3,2) estimated parameters (AIC recommended) produced an ASE = 3.516085. The selected model will be the one with the lower ASE score and it is:

ARUMA with estimated AR(1) paramters -> ASE = 3.44


Now we create a univariate neural network model.
```{r Prob 3a.b - Univariate Neural Network Model}
set.seed(2)

# create training data split
rmortTrain = ts(data$rmort[1:478],frequency=52) 

# create test data split - last 30 weeks 
rmortTest = ts(data$rmort[479:508],frequency=52)

# fit the NN model, let the function identify the best diff order(s)
fit.mlp=mlp(rmortTrain,difforder=NULL,allow.det.season = FALSE)
fit.mlp

# plot the NN
plot(fit.mlp)

# forecast the test data + 5 more weeks
fore.mlp=forecast(fit.mlp,h=35)

# plot the forecast of the test data
plot(fore.mlp)


# Plot forecast of test data over actual data
plot(seq(1,508,1), data$rmort, type = "l",xlim = c(0,508), ylab = "Respiratory Mortality", main = "Neural Net Resp-Mortality Predicted Over Actual Last 30 Weeks")
lines(seq(479,508,1), fore.mlp$mean[1:30], type = "l", col = "red")


# calc ASE based on the forecasted and actual test data
ASE3 = mean((data$rmort[479:508]-fore.mlp$mean[1:30])^2)
ASE3
```

Next, a multilayer perceptron (MLP) function was used to create a neural network model. Default parameters were used in addition to telling the function to identify the best difference order(s) and restricting modeling seasonality with deterministic dummies.

The neural network model has 5 hidden nodes and 20 repetitions. There were 10 univariate lags which are the inputs. The neural network model produced and ASE = 10.23 which is not as good as the ARUMA model. Predicted values appear to be above the actuals.

Neural Network Model -> ASE = 10.23

```{r Prob 3a.c - Ensemble Model}
# build ensemble using ave of the two forecasts
ensemble  = (foreAR1$f + fore.mlp$mean[1:30])/2

# plot the ensemble results
plot(seq(1,508,1), data$rmort, type = "l",xlim = c(0,508), ylab = "Respiratory Mortality", main = "Ensemble Resp-Mortality Predicted Over Actual Last 30 Weeks")
lines(seq(479,508,1), ensemble, type = "l", col = "green")

# calc ensemble ASE
ASE4 = mean((data$rmort[(508-30+1):508] - ensemble)^2)
ASE4

# forecast of next 5 weeks
foreAR1.all = append(foreAR1$f,foreAR1.new$f) # AR1 data with 5 week forecast
ensemble.new = (foreAR1.all + fore.mlp$mean[1:35])/2
ensemble.new[31:35] # predicted 5 week values

plot(seq(1,508,1), data$rmort, type = "l",xlim = c(0,515), ylab = "Respiratory Mortality", main = "Ensemble Resp-Mortality Predicted Over Actual Last 30 Weeks Plus 5 Week Forecast")
lines(seq(479,513,1), ensemble.new, type = "l", col = "blue")

```

An ensemble model was built using the average of the ARUMA and Neural Network forecasts. The predicted values are a little above the actual values but this model produced the lowest ASE at 2.29. Since this model produced the lowest ASE, it is the recommended model for the univariate analysis or repiratory mortalty. The forecasted next 5 weeks resembles the previous patterns with values of (12.31, 12.65, 12.21, 12.98, 13.39).

Ensemble Model -> ASE = 2.29 (selected univariate model)




###4a. Perform a multivariate analysis using at least a VAR or MLR with correlated errors and a MLP model. Clearly explain how you arrived at the final model. Use forecasted values of the predictors where appropriate.

View correlaiton between all variables.
```{r Check correlation between variables}
par(mfrow=c(4,4))
plotts.wge(data$tempr)
plotts.wge(data$rh)
plotts.wge(data$co)
plotts.wge(data$so2)
plotts.wge(data$no2)
plotts.wge(data$hycarb)
plotts.wge(data$o3)
plotts.wge(data$part)
# variables appear to be serially correlated

pairs.panels(data[5:12], 
             method = "pearson",   # correlation method
             hist.col = "#00AFBB",
             density = TRUE,       # show density plots
             ellipses = TRUE       # show correlation ellipses
             )
# the correlation matrix shows strong correlation between the following variables
# - co2, no2
# - co2, hycarb
# - tempr, o3
# - so2, no2
# - so2, hycarb
# - no2, hycarb

# plot the temp
plotts.sample.wge(data$tempr)
acf(data$tempr[1:254])    # acf stationarity check
acf(data$tempr[255:508])  # acf stationarity check

# plot the rh
plotts.sample.wge(data$rh)
acf(data$rh[1:254])   # acf stationarity check
acf(data$rh[255:508]) # acf stationarity check

# plot the co
plotts.sample.wge(data$co)
acf(data$co[1:254])   # acf stationarity check
acf(data$co[255:508]) # acf stationarity check

# plot the so2
plotts.sample.wge(data$so2)
acf(data$so2[1:254])   # acf stationarity check
acf(data$so2[255:508]) # acf stationarity check

# plot the no2
plotts.sample.wge(data$no2)
acf(data$no2[1:254])   # acf stationarity check
acf(data$no2[255:508]) # acf stationarity check

# plot the rh
plotts.sample.wge(data$hycarb)
acf(data$hycarb[1:254])   # acf stationarity check
acf(data$hycarb[255:508]) # acf stationarity check

# plot the 03
plotts.sample.wge(data$o3)
acf(data$o3[1:254])   # acf stationarity check
acf(data$o3[255:508]) # acf stationarity check

# plot the pollution
plotts.sample.wge(data$part)
acf(data$part[1:254])    # acf stationarity check
acf(data$part[255:508])  # acf stationarity check

# since the data is weekly, remove weekly trend. some var realizations are noisy but seasonality is still seen
diftemp = artrans.wge(data$tempr,c(rep(0,51),1))
acf(diftemp,lag.max = 50)

difrh = artrans.wge(data$rh,c(rep(0,51),1))
acf(difrh,lag.max = 50)

# nope
difco = artrans.wge(data$co,c(rep(0,51),1))
acf(difco,lag.max = 50)
difco_51.1 = artrans.wge(difco,phi.tr=1)
acf(difco_51.1,lag.max = 50)

# nope
difso2 = artrans.wge(data$so2,c(rep(0,51),1))
acf(difso2,lag.max = 50)
difso2_52.1=artrans.wge(difso2,phi.tr = 1)
acf(difso2_52.1,lag.max = 50)

difno2 = artrans.wge(data$no2,c(rep(0,51),1))
acf(difno2,lag.max = 50)

# nope
difhycarb = artrans.wge(data$hycarb,c(rep(0,51),1))
acf(difhycarb,lag.max = 50)
difhycarb_52.1=artrans.wge(difhycarb,phi.tr = 1)
acf(difhycarb_52.1,lag.max = 50)

difo3 = artrans.wge(data$o3,c(rep(0,51),1))
acf(difo3,lag.max = 50)

difpart = artrans.wge(data$part,c(rep(0,51),1))
acf(difo3,lag.max = 50)
```



###4b. Fit and evaluate an ensemble model from the models you fit in 4a.
```{r}

```

###4c. Compare these models and describe which multivariate model you feel is the best and why.
```{r}

```

###5. Use the model you feel is most useful to forecat the next 5 weeks of respiratory mortality.
```{r}

```


# Check for white noise
ljung.wge(dif2)                                   # Reject Ho, p-value=6.7e-11 so Ljung-Box with K=24 indicates not white
ljung.wge(dif2, K = 48)                           # Reject Ho, p-value=4.1e-08 so Ljung-Box with K=48 indicates not white
acf(dif2,lag.max = 50)                            # Box-Jenkins, not quite white but close, lag1 is still a bit strong


